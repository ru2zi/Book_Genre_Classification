{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ru2zi/Book_Genre_Classification/blob/main/inception_bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "uzroVtrsQo5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.version.VERSION)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-26T01:53:57.632954Z",
          "iopub.execute_input": "2023-05-26T01:53:57.633458Z",
          "iopub.status.idle": "2023-05-26T01:53:57.641158Z",
          "shell.execute_reply.started": "2023-05-26T01:53:57.633418Z",
          "shell.execute_reply": "2023-05-26T01:53:57.639777Z"
        },
        "trusted": true,
        "id": "jlLrRts9Qo5l",
        "outputId": "816e3d73-b049-465f-c171-46e4a9b7385c"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "2.11.0\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import tensorflow_hub as hub"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-28T15:07:23.226165Z",
          "iopub.execute_input": "2023-05-28T15:07:23.226989Z",
          "iopub.status.idle": "2023-05-28T15:07:33.537720Z",
          "shell.execute_reply.started": "2023-05-28T15:07:23.226955Z",
          "shell.execute_reply": "2023-05-28T15:07:33.536250Z"
        },
        "trusted": true,
        "id": "PeiNG3qHQo5m",
        "outputId": "136c4454-a1ef-4be5-a2ba-8d1d0c6a0b6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"TF Version: \", tf.__version__)\n",
        "print(\"Eager mode: \", tf.executing_eagerly())\n",
        "print(\"Hub version: \", hub.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-26T14:43:48.803169Z",
          "iopub.execute_input": "2023-05-26T14:43:48.804213Z",
          "iopub.status.idle": "2023-05-26T14:43:48.821351Z",
          "shell.execute_reply.started": "2023-05-26T14:43:48.804163Z",
          "shell.execute_reply": "2023-05-26T14:43:48.819936Z"
        },
        "trusted": true,
        "id": "1e4N36BjQo5m",
        "outputId": "7b979f1d-92f0-4f9f-e3f9-20fdbeff802f"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "TF Version:  2.11.0\nEager mode:  True\nHub version:  0.12.0\nGPU is NOT AVAILABLE\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "evcUkbhKQo5n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import AdamW\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "\n",
        "import tokenizers\n",
        "import transformers\n",
        "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
        "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-29T08:12:48.596594Z",
          "iopub.execute_input": "2023-05-29T08:12:48.596945Z",
          "iopub.status.idle": "2023-05-29T08:13:03.135132Z",
          "shell.execute_reply.started": "2023-05-29T08:12:48.596918Z",
          "shell.execute_reply": "2023-05-29T08:13:03.133798Z"
        },
        "trusted": true,
        "id": "0X6kviB3Qo5n",
        "outputId": "4087f202-aa9e-4e46-b66b-fb0bfae414a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/kaggle/input/jbnu-swuniv-ai/train_data.csv\")\n",
        "df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-29T08:13:08.215236Z",
          "iopub.execute_input": "2023-05-29T08:13:08.215570Z",
          "iopub.status.idle": "2023-05-29T08:13:08.350022Z",
          "shell.execute_reply.started": "2023-05-29T08:13:08.215544Z",
          "shell.execute_reply": "2023-05-29T08:13:08.348808Z"
        },
        "trusted": true,
        "id": "X-iGBVBnQo5o",
        "outputId": "16371b97-a7f7-47fd-d0fb-f80ad906c085"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 5,
          "output_type": "execute_result",
          "data": {
            "text/plain": "          id        Filename  \\\n0          0  1101903236.jpg   \n1          1  0804139857.jpg   \n2          2  0765334798.jpg   \n3          3  0446310786.jpg   \n4          4  1143002598.jpg   \n...      ...             ...   \n68677  68677  0735582912.jpg   \n68678  68678  1433111020.jpg   \n68679  68679  0444853510.jpg   \n68680  68680  1449465447.jpg   \n68681  68681  0736948481.jpg   \n\n                                                   Title  \\\n0      The Oz Family Kitchen: More Than 100 Simple an...   \n1      Living with Intent: My Somewhat Messy Journey ...   \n2                    Redshirts: A Novel with Three Codas   \n3                                  To Kill a Mockingbird   \n4      Canning and Preserving of Food Products with B...   \n...                                                  ...   \n68677  Casenote Legal Briefs: Family Law, Keyed to Ha...   \n68678  Communication for Families in Crisis: Theories...   \n68679  Fine-line Lithography (Materials processing, t...   \n68680                       Magic Eye 2016 Wall Calendar   \n68681     The World's Greatest Collection of Clean Jokes   \n\n                             label  \n0            Cookbooks, Food, Wine  \n1                        Self Help  \n2         Science Fiction, Fantasy  \n3      Mystery, Thriller, Suspense  \n4            Cookbooks, Food, Wine  \n...                            ...  \n68677                          Law  \n68678                          Law  \n68679            Arts, Photography  \n68680                    Calendars  \n68681         Humor, Entertainment  \n\n[68682 rows x 4 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Filename</th>\n      <th>Title</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1101903236.jpg</td>\n      <td>The Oz Family Kitchen: More Than 100 Simple an...</td>\n      <td>Cookbooks, Food, Wine</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0804139857.jpg</td>\n      <td>Living with Intent: My Somewhat Messy Journey ...</td>\n      <td>Self Help</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0765334798.jpg</td>\n      <td>Redshirts: A Novel with Three Codas</td>\n      <td>Science Fiction, Fantasy</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0446310786.jpg</td>\n      <td>To Kill a Mockingbird</td>\n      <td>Mystery, Thriller, Suspense</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>1143002598.jpg</td>\n      <td>Canning and Preserving of Food Products with B...</td>\n      <td>Cookbooks, Food, Wine</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>68677</th>\n      <td>68677</td>\n      <td>0735582912.jpg</td>\n      <td>Casenote Legal Briefs: Family Law, Keyed to Ha...</td>\n      <td>Law</td>\n    </tr>\n    <tr>\n      <th>68678</th>\n      <td>68678</td>\n      <td>1433111020.jpg</td>\n      <td>Communication for Families in Crisis: Theories...</td>\n      <td>Law</td>\n    </tr>\n    <tr>\n      <th>68679</th>\n      <td>68679</td>\n      <td>0444853510.jpg</td>\n      <td>Fine-line Lithography (Materials processing, t...</td>\n      <td>Arts, Photography</td>\n    </tr>\n    <tr>\n      <th>68680</th>\n      <td>68680</td>\n      <td>1449465447.jpg</td>\n      <td>Magic Eye 2016 Wall Calendar</td>\n      <td>Calendars</td>\n    </tr>\n    <tr>\n      <th>68681</th>\n      <td>68681</td>\n      <td>0736948481.jpg</td>\n      <td>The World's Greatest Collection of Clean Jokes</td>\n      <td>Humor, Entertainment</td>\n    </tr>\n  </tbody>\n</table>\n<p>68682 rows × 4 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_values = df['label'].unique().tolist()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-29T08:13:13.918105Z",
          "iopub.execute_input": "2023-05-29T08:13:13.918760Z",
          "iopub.status.idle": "2023-05-29T08:13:13.928455Z",
          "shell.execute_reply.started": "2023-05-29T08:13:13.918698Z",
          "shell.execute_reply": "2023-05-29T08:13:13.927039Z"
        },
        "trusted": true,
        "id": "5-Jdx8XCQo5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_values"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-29T08:13:20.638549Z",
          "iopub.execute_input": "2023-05-29T08:13:20.639439Z",
          "iopub.status.idle": "2023-05-29T08:13:20.645351Z",
          "shell.execute_reply.started": "2023-05-29T08:13:20.639407Z",
          "shell.execute_reply": "2023-05-29T08:13:20.643906Z"
        },
        "trusted": true,
        "id": "Q-zmww69Qo5o",
        "outputId": "2111a9b9-dd42-472d-8f3f-6511db50dcf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 10,
          "output_type": "execute_result",
          "data": {
            "text/plain": "['Cookbooks, Food, Wine',\n 'Self Help',\n 'Science Fiction, Fantasy',\n 'Mystery, Thriller, Suspense',\n 'Health, Fitness, Dieting',\n 'Humor, Entertainment',\n 'Religion, Spirituality',\n 'Computers, Technology',\n 'Reference',\n 'Medical Books',\n 'Test Preparation',\n 'Engineering, Transportation',\n 'Childrens Books',\n 'Arts, Photography',\n 'Science, Math',\n 'Parenting, Relationships',\n 'Literature, Fiction',\n 'Calendars',\n 'Sports, Outdoors',\n 'Travel',\n 'Crafts, Hobbies, Home',\n 'Law',\n 'Biographies, Memoirs',\n 'Education, Teaching']"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Step 1: Determine the number of samples per class\n",
        "total_samples = 1000\n",
        "num_classes = 24\n",
        "samples_per_class = total_samples // num_classes\n",
        "\n",
        "# Step 2: Split the original dataset into separate dataframes based on class labels\n",
        "class_dataframes = []\n",
        "for class_label in unique_values:\n",
        "    class_df = df[df['label'] == class_label]  # Replace 'class_label' with the actual column name\n",
        "    class_dataframes.append(class_df)\n",
        "\n",
        "# Step 4: Create an empty dataframe to store the extracted samples\n",
        "sample_df = pd.DataFrame()\n",
        "\n",
        "# Step 5: Extract samples from each class\n",
        "for class_df in class_dataframes:\n",
        "    extracted_samples = class_df.head(samples_per_class)\n",
        "    sample_df = sample_df.append(extracted_samples)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-28T15:08:00.852739Z",
          "iopub.execute_input": "2023-05-28T15:08:00.853174Z",
          "iopub.status.idle": "2023-05-28T15:08:01.019901Z",
          "shell.execute_reply.started": "2023-05-28T15:08:00.853145Z",
          "shell.execute_reply": "2023-05-28T15:08:01.018600Z"
        },
        "trusted": true,
        "id": "LYiN1mgXQo5p",
        "outputId": "f011db94-afa6-4660-bb2c-54a9ee15b9ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_34/866014983.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  sample_df = sample_df.append(extracted_samples)\n/tmp/ipykernel_34/866014983.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  sample_df = sample_df.append(extracted_samples)\n/tmp/ipykernel_34/866014983.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  sample_df = sample_df.append(extracted_samples)\n/tmp/ipykernel_34/866014983.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  sample_df = sample_df.append(extracted_samples)\n/tmp/ipykernel_34/866014983.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  sample_df = sample_df.append(extracted_samples)\n/tmp/ipykernel_34/866014983.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  sample_df = sample_df.append(extracted_samples)\n/tmp/ipykernel_34/866014983.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  sample_df = sample_df.append(extracted_samples)\n/tmp/ipykernel_34/866014983.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  sample_df = sample_df.append(extracted_samples)\n/tmp/ipykernel_34/866014983.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  sample_df = sample_df.append(extracted_samples)\n/tmp/ipykernel_34/866014983.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  sample_df = sample_df.append(extracted_samples)\n/tmp/ipykernel_34/866014983.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  sample_df = sample_df.append(extracted_samples)\n/tmp/ipykernel_34/866014983.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  sample_df = sample_df.append(extracted_samples)\n/tmp/ipykernel_34/866014983.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  sample_df = sample_df.append(extracted_samples)\n/tmp/ipykernel_34/866014983.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  sample_df = sample_df.append(extracted_samples)\n/tmp/ipykernel_34/866014983.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  sample_df = sample_df.append(extracted_samples)\n/tmp/ipykernel_34/866014983.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  sample_df = sample_df.append(extracted_samples)\n/tmp/ipykernel_34/866014983.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  sample_df = sample_df.append(extracted_samples)\n/tmp/ipykernel_34/866014983.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  sample_df = sample_df.append(extracted_samples)\n/tmp/ipykernel_34/866014983.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  sample_df = sample_df.append(extracted_samples)\n/tmp/ipykernel_34/866014983.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  sample_df = sample_df.append(extracted_samples)\n/tmp/ipykernel_34/866014983.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  sample_df = sample_df.append(extracted_samples)\n/tmp/ipykernel_34/866014983.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  sample_df = sample_df.append(extracted_samples)\n/tmp/ipykernel_34/866014983.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  sample_df = sample_df.append(extracted_samples)\n/tmp/ipykernel_34/866014983.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  sample_df = sample_df.append(extracted_samples)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "data_dir = \"/kaggle/input/jbnu-swuniv-ai/train/\"\n",
        "\n",
        "def create_image_path(row):\n",
        "    return os.path.join(data_dir, row['label'], row['Filename'])\n",
        "\n",
        "sample_df['image_path'] = sample_df.apply(create_image_path, axis=1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-28T15:08:05.803722Z",
          "iopub.execute_input": "2023-05-28T15:08:05.804110Z",
          "iopub.status.idle": "2023-05-28T15:08:05.827982Z",
          "shell.execute_reply.started": "2023-05-28T15:08:05.804081Z",
          "shell.execute_reply": "2023-05-28T15:08:05.826879Z"
        },
        "trusted": true,
        "id": "taAWwkm4Qo5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "sample_df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-27T09:49:51.471626Z",
          "iopub.execute_input": "2023-05-27T09:49:51.472131Z",
          "iopub.status.idle": "2023-05-27T09:49:51.494301Z",
          "shell.execute_reply.started": "2023-05-27T09:49:51.472092Z",
          "shell.execute_reply": "2023-05-27T09:49:51.493048Z"
        },
        "id": "1FutVprqQo5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "sample_df[\"label_encode\"] = le.fit_transform(sample_df.label)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-28T15:08:11.047210Z",
          "iopub.execute_input": "2023-05-28T15:08:11.048629Z",
          "iopub.status.idle": "2023-05-28T15:08:11.057778Z",
          "shell.execute_reply.started": "2023-05-28T15:08:11.048561Z",
          "shell.execute_reply": "2023-05-28T15:08:11.056449Z"
        },
        "trusted": true,
        "id": "NIvO3hu3Qo5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, test_df = train_test_split(sample_df, test_size=0.2, random_state=42)\n",
        "train_df, test_df = train_df.reset_index(drop=True), test_df.reset_index(drop=True)\n",
        "print(\"Train:\", train_df.shape)\n",
        "print(\"Test:\", test_df.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-28T15:08:14.753298Z",
          "iopub.execute_input": "2023-05-28T15:08:14.753817Z",
          "iopub.status.idle": "2023-05-28T15:08:14.769376Z",
          "shell.execute_reply.started": "2023-05-28T15:08:14.753775Z",
          "shell.execute_reply": "2023-05-28T15:08:14.765151Z"
        },
        "trusted": true,
        "id": "dBKn7x1cQo5p",
        "outputId": "9f35dd06-d540-404a-ecc7-67f930234c31"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Train: (787, 6)\nTest: (197, 6)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-28T15:08:17.407328Z",
          "iopub.execute_input": "2023-05-28T15:08:17.407837Z",
          "iopub.status.idle": "2023-05-28T15:08:17.428032Z",
          "shell.execute_reply.started": "2023-05-28T15:08:17.407798Z",
          "shell.execute_reply": "2023-05-28T15:08:17.426416Z"
        },
        "trusted": true,
        "id": "ppK7oJbOQo5p",
        "outputId": "b7bf2446-63ab-4776-9b37-57abcfcf7199"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 10,
          "output_type": "execute_result",
          "data": {
            "text/plain": "       id        Filename                                              Title  \\\n0    1355  0137152523.jpg  Assessment Procedures for Counselors and Helpi...   \n1     566  0847826902.jpg                           Classic Golf Instruction   \n2     232  1594744971.jpg  Stuff Every Husband Should Know (Pocket Compan...   \n3     742  1423484487.jpg  Secrets of Negotiating a Record Contract: Musi...   \n4     772  0316212954.jpg              Baseball World Series (Little League)   \n..    ...             ...                                                ...   \n782   527  B00EAP9IPO.jpg                                 Kafka on the Shore   \n783   614  0465014542.jpg  Creating Minds: An Anatomy of Creativity as Se...   \n784   712  0696235439.jpg  Ideas & How-To: Outdoor Kitchens (Better Homes...   \n785   746  160971699X.jpg  FSOT Flashcard Study System: FSOT Exam Practic...   \n786   455  1588460754.jpg  Ravenloft Campaign Setting: Core Rulebook (d20...   \n\n                        label  \\\n0         Education, Teaching   \n1            Sports, Outdoors   \n2                   Reference   \n3                         Law   \n4             Childrens Books   \n..                        ...   \n782  Science Fiction, Fantasy   \n783    Religion, Spirituality   \n784     Crafts, Hobbies, Home   \n785          Test Preparation   \n786  Science Fiction, Fantasy   \n\n                                            image_path  label_encode  \n0    /kaggle/input/jbnu-swuniv-ai/train/Education, ...             7  \n1    /kaggle/input/jbnu-swuniv-ai/train/Sports, Out...            21  \n2    /kaggle/input/jbnu-swuniv-ai/train/Reference/1...            16  \n3    /kaggle/input/jbnu-swuniv-ai/train/Law/1423484...            11  \n4    /kaggle/input/jbnu-swuniv-ai/train/Childrens B...             3  \n..                                                 ...           ...  \n782  /kaggle/input/jbnu-swuniv-ai/train/Science Fic...            18  \n783  /kaggle/input/jbnu-swuniv-ai/train/Religion, S...            17  \n784  /kaggle/input/jbnu-swuniv-ai/train/Crafts, Hob...             6  \n785  /kaggle/input/jbnu-swuniv-ai/train/Test Prepar...            22  \n786  /kaggle/input/jbnu-swuniv-ai/train/Science Fic...            18  \n\n[787 rows x 6 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Filename</th>\n      <th>Title</th>\n      <th>label</th>\n      <th>image_path</th>\n      <th>label_encode</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1355</td>\n      <td>0137152523.jpg</td>\n      <td>Assessment Procedures for Counselors and Helpi...</td>\n      <td>Education, Teaching</td>\n      <td>/kaggle/input/jbnu-swuniv-ai/train/Education, ...</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>566</td>\n      <td>0847826902.jpg</td>\n      <td>Classic Golf Instruction</td>\n      <td>Sports, Outdoors</td>\n      <td>/kaggle/input/jbnu-swuniv-ai/train/Sports, Out...</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>232</td>\n      <td>1594744971.jpg</td>\n      <td>Stuff Every Husband Should Know (Pocket Compan...</td>\n      <td>Reference</td>\n      <td>/kaggle/input/jbnu-swuniv-ai/train/Reference/1...</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>742</td>\n      <td>1423484487.jpg</td>\n      <td>Secrets of Negotiating a Record Contract: Musi...</td>\n      <td>Law</td>\n      <td>/kaggle/input/jbnu-swuniv-ai/train/Law/1423484...</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>772</td>\n      <td>0316212954.jpg</td>\n      <td>Baseball World Series (Little League)</td>\n      <td>Childrens Books</td>\n      <td>/kaggle/input/jbnu-swuniv-ai/train/Childrens B...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>782</th>\n      <td>527</td>\n      <td>B00EAP9IPO.jpg</td>\n      <td>Kafka on the Shore</td>\n      <td>Science Fiction, Fantasy</td>\n      <td>/kaggle/input/jbnu-swuniv-ai/train/Science Fic...</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>783</th>\n      <td>614</td>\n      <td>0465014542.jpg</td>\n      <td>Creating Minds: An Anatomy of Creativity as Se...</td>\n      <td>Religion, Spirituality</td>\n      <td>/kaggle/input/jbnu-swuniv-ai/train/Religion, S...</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>784</th>\n      <td>712</td>\n      <td>0696235439.jpg</td>\n      <td>Ideas &amp; How-To: Outdoor Kitchens (Better Homes...</td>\n      <td>Crafts, Hobbies, Home</td>\n      <td>/kaggle/input/jbnu-swuniv-ai/train/Crafts, Hob...</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>785</th>\n      <td>746</td>\n      <td>160971699X.jpg</td>\n      <td>FSOT Flashcard Study System: FSOT Exam Practic...</td>\n      <td>Test Preparation</td>\n      <td>/kaggle/input/jbnu-swuniv-ai/train/Test Prepar...</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>786</th>\n      <td>455</td>\n      <td>1588460754.jpg</td>\n      <td>Ravenloft Campaign Setting: Core Rulebook (d20...</td>\n      <td>Science Fiction, Fantasy</td>\n      <td>/kaggle/input/jbnu-swuniv-ai/train/Science Fic...</td>\n      <td>18</td>\n    </tr>\n  </tbody>\n</table>\n<p>787 rows × 6 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts = train_df[\"Title\"].to_list() # Features (not-tokenized yet)\n",
        "train_labels = train_df[\"label_encode\"].to_list() # Labels"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-26T01:14:38.797879Z",
          "iopub.execute_input": "2023-05-26T01:14:38.799050Z",
          "iopub.status.idle": "2023-05-26T01:14:38.804421Z",
          "shell.execute_reply.started": "2023-05-26T01:14:38.799008Z",
          "shell.execute_reply": "2023-05-26T01:14:38.803333Z"
        },
        "trusted": true,
        "id": "dzpAUnz3Qo5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split Train and Validation data\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-26T01:16:03.506849Z",
          "iopub.execute_input": "2023-05-26T01:16:03.507301Z",
          "iopub.status.idle": "2023-05-26T01:16:03.515822Z",
          "shell.execute_reply.started": "2023-05-26T01:16:03.507261Z",
          "shell.execute_reply": "2023-05-26T01:16:03.514310Z"
        },
        "trusted": true,
        "id": "g5TPvrlKQo5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#입력 텍스트를 토큰으로 분할하고 이에 대응하는 정수 인덱스를 생성합니다. 이렇게 생성된 토큰과 인덱스는 BERT 모델의 입력으로 사용"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-24T12:44:26.198360Z",
          "iopub.execute_input": "2023-05-24T12:44:26.198779Z",
          "iopub.status.idle": "2023-05-24T12:44:26.220176Z",
          "shell.execute_reply.started": "2023-05-24T12:44:26.198743Z",
          "shell.execute_reply": "2023-05-24T12:44:26.219291Z"
        },
        "trusted": true,
        "id": "BjarbX9TQo5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import tensorflow_hub as hub"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-27T09:51:48.200356Z",
          "iopub.execute_input": "2023-05-27T09:51:48.200777Z",
          "iopub.status.idle": "2023-05-27T09:51:48.207863Z",
          "shell.execute_reply.started": "2023-05-27T09:51:48.200748Z",
          "shell.execute_reply": "2023-05-27T09:51:48.206390Z"
        },
        "trusted": true,
        "id": "a27thtRrQo5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers --yes"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-26T02:22:47.713823Z",
          "iopub.execute_input": "2023-05-26T02:22:47.714303Z",
          "iopub.status.idle": "2023-05-26T02:22:49.443675Z",
          "shell.execute_reply.started": "2023-05-26T02:22:47.714261Z",
          "shell.execute_reply": "2023-05-26T02:22:49.442244Z"
        },
        "trusted": true,
        "id": "ip_yrIcTQo5q",
        "outputId": "8ff494b1-3a9a-4fc1-fcb9-45fa411f832d"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "\nUsage:   \n  pip install [options] <requirement specifier> [package-index-options] ...\n  pip install [options] -r <requirements file> [package-index-options] ...\n  pip install [options] [-e] <vcs project url> ...\n  pip install [options] [-e] <local project path> ...\n  pip install [options] <archive url/path> ...\n\nno such option: --yes\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "module_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/1\"\n",
        "bert_layer = hub.KerasLayer(module_url, trainable=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-27T11:58:32.864067Z",
          "iopub.execute_input": "2023-05-27T11:58:32.864528Z",
          "iopub.status.idle": "2023-05-27T11:59:10.609712Z",
          "shell.execute_reply.started": "2023-05-27T11:58:32.864495Z",
          "shell.execute_reply": "2023-05-27T11:59:10.608229Z"
        },
        "trusted": true,
        "id": "wT-LQZE6Qo5q",
        "outputId": "28fb7a17-2e10-42dc-c07a-88dfb730a41f"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "CPU times: user 25.8 s, sys: 5.74 s, total: 31.5 s\nWall time: 37.7 s\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-28T15:08:32.183228Z",
          "iopub.execute_input": "2023-05-28T15:08:32.183738Z",
          "iopub.status.idle": "2023-05-28T15:08:35.960210Z",
          "shell.execute_reply.started": "2023-05-28T15:08:32.183674Z",
          "shell.execute_reply": "2023-05-28T15:08:35.958783Z"
        },
        "trusted": true,
        "id": "1iBAotzdQo5q",
        "outputId": "2b06fccf-3fb3-4b78-b677-c4bb29173c81",
        "colab": {
          "referenced_widgets": [
            "100691061fa84987889a960ea504e20c",
            "b0c95519ba51432dbb969835ec2e0c97",
            "c2ffe97b340c4f518b6b3a826de6103d"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "100691061fa84987889a960ea504e20c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b0c95519ba51432dbb969835ec2e0c97"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c2ffe97b340c4f518b6b3a826de6103d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-27T09:53:32.835469Z",
          "iopub.execute_input": "2023-05-27T09:53:32.835958Z",
          "iopub.status.idle": "2023-05-27T09:53:32.844523Z",
          "shell.execute_reply.started": "2023-05-27T09:53:32.835927Z",
          "shell.execute_reply": "2023-05-27T09:53:32.842773Z"
        },
        "trusted": true,
        "id": "k_4tNdQrQo5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_and_prepare_data(sample_df['image_path'][7])"
      ],
      "metadata": {
        "id": "FlInBCnSQo5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = sample_df['Title'].apply(lambda x: len(x)).max()\n",
        "print(max_length)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-28T08:35:56.316627Z",
          "iopub.execute_input": "2023-05-28T08:35:56.317027Z",
          "iopub.status.idle": "2023-05-28T08:35:56.324728Z",
          "shell.execute_reply.started": "2023-05-28T08:35:56.316998Z",
          "shell.execute_reply": "2023-05-28T08:35:56.323806Z"
        },
        "trusted": true,
        "id": "TiHqYtELQo5r",
        "outputId": "d9c36bd7-1e88-4fef-a563-e3174aa26934"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "199\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 300"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-28T08:36:17.282688Z",
          "iopub.execute_input": "2023-05-28T08:36:17.283086Z",
          "iopub.status.idle": "2023-05-28T08:36:17.287548Z",
          "shell.execute_reply.started": "2023-05-28T08:36:17.283057Z",
          "shell.execute_reply": "2023-05-28T08:36:17.286545Z"
        },
        "trusted": true,
        "id": "dIM5h_40Qo5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pa= sample_df['image_path'][0].split(os.sep)\n",
        "pa[-2]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-28T15:13:36.254136Z",
          "iopub.execute_input": "2023-05-28T15:13:36.254597Z",
          "iopub.status.idle": "2023-05-28T15:13:36.261505Z",
          "shell.execute_reply.started": "2023-05-28T15:13:36.254557Z",
          "shell.execute_reply": "2023-05-28T15:13:36.260239Z"
        },
        "trusted": true,
        "id": "G3EJjvs5Qo5r",
        "outputId": "8742315b-89b8-43a1-e5a6-bd9ded23395e"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 13,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'Cookbooks, Food, Wine'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import re\n",
        "import os\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "# 전처리 함수들\n",
        "def preprocess_text(sen):\n",
        "    # HTML 태그 제거\n",
        "    sentence = remove_tags(sen)\n",
        "    # 구두점과 숫자 제거\n",
        "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
        "    # 단일 문자 제거\n",
        "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
        "    # 여러 개의 공백 제거\n",
        "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
        "    sentence = sentence.lower()\n",
        "    return sentence\n",
        "\n",
        "def remove_tags(text):\n",
        "    return TAG_RE.sub('', text)\n",
        "\n",
        "TAG_RE = re.compile(r'<[^>]+>')\n",
        "vec_preprocess_text = np.vectorize(preprocess_text)\n",
        "\n",
        "# 텍스트 데이터 처리 함수들\n",
        "def get_tokens(text, tokenizer, max_length=300):\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"]\n",
        "    length = len(tokens)\n",
        "    if length > max_length:\n",
        "        tokens = tokens[:max_length]\n",
        "    return tokens, length\n",
        "\n",
        "def get_masks(text, tokenizer, max_length):\n",
        "    \"\"\"패딩을 위한 마스크\"\"\"\n",
        "    tokens, length = get_tokens(text, tokenizer, max_length)\n",
        "    return np.asarray([1] * len(tokens) + [0] * (max_length - len(tokens)))\n",
        "\n",
        "vec_get_masks = np.vectorize(get_masks, signature='(),(),()->(n)')\n",
        "\n",
        "def get_segments(text, tokenizer, max_length):\n",
        "    \"\"\"세그먼트: 첫 번째 시퀀스는 0, 두 번째 시퀀스는 1\"\"\"\n",
        "    tokens, length = get_tokens(text, tokenizer, max_length)\n",
        "    segments = []\n",
        "    current_segment_id = 0\n",
        "    for token in tokens:\n",
        "        segments.append(current_segment_id)\n",
        "        if token == \"[SEP]\":\n",
        "            current_segment_id = 1\n",
        "    return np.asarray(segments + [0] * (max_length - len(tokens)))\n",
        "\n",
        "vec_get_segments = np.vectorize(get_segments, signature='(),(),()->(n)')\n",
        "\n",
        "def get_ids(text, tokenizer, max_length):\n",
        "    \"\"\"Tokenizer vocab에서 토큰 ID 가져오기\"\"\"\n",
        "    tokens, length = get_tokens(text, tokenizer)\n",
        "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "    input_ids = np.asarray(token_ids + [0] * (max_length - length))\n",
        "    return input_ids\n",
        "\n",
        "vec_get_ids = np.vectorize(get_ids, signature='(),(),()->(n)')\n",
        "\n",
        "def get_text(image_path, df):\n",
        "    parts = image_path.split(os.sep)\n",
        "    image_name = parts[-1]\n",
        "    text = df.loc[df['Filename'] == image_name, 'Title'].values[0]\n",
        "    return text\n",
        "\n",
        "vec_get_text = np.vectorize(get_text)\n",
        "\n",
        "\n",
        "def prepare_text(image_path):\n",
        "    #Preparing texts\n",
        "\n",
        "    texts = vec_get_text(image_path)\n",
        "\n",
        "    text_array = vec_preprocess_text(texts)\n",
        "\n",
        "    ids = vec_get_ids(text_array,\n",
        "                      tokenizer,\n",
        "                      max_length).squeeze().astype(np.int32)\n",
        "    masks = vec_get_masks(text_array,\n",
        "                          tokenizer,\n",
        "                          max_length).squeeze().astype(np.int32)\n",
        "    segments = vec_get_segments(text_array,\n",
        "                                tokenizer,\n",
        "                                max_length).squeeze().astype(np.int32)\n",
        "\n",
        "    return ids, segments, masks\n",
        "\n",
        "# Images preprocessing\n",
        "def load_image(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.resize(image, (299, 299))\n",
        "    image = image / 255\n",
        "    image = image.astype(np.float32)\n",
        "\n",
        "    parts = image_path.split(os.sep)\n",
        "    labels = parts[-2]\n",
        "    labels = labels.astype(np.int32)\n",
        "\n",
        "    return image, labels\n",
        "\n",
        "vec_load_image = np.vectorize(load_image, signature = '()->(r,c,d),(s)')\n",
        "\n",
        "\n",
        "\n",
        "def prepare_data(paths):\n",
        "    #Images and labels\n",
        "    images, labels = tf.numpy_function(vec_load_image,\n",
        "                                      [paths],\n",
        "                                      [tf.float32,\n",
        "                                        tf.int32])\n",
        "\n",
        "\n",
        "    [ids, segments, masks, ] = tf.numpy_function(prepare_text,\n",
        "                                              [paths],\n",
        "                                              [tf.int32,\n",
        "                                               tf.int32,\n",
        "                                               tf.int32])\n",
        "    images.set_shape([None, img_width, img_height, depth])\n",
        "    labels.set_shape([None, nClasses])\n",
        "    ids.set_shape([None, max_length])\n",
        "    masks.set_shape([None, max_length])\n",
        "    segments.set_shape([None, max_length])\n",
        "    return ({\"input_word_ids\": ids,\n",
        "             \"input_mask\": masks,\n",
        "             \"segment_ids\": segments,\n",
        "             \"image\": images},\n",
        "            {\"class\": labels})\n",
        "\n",
        "\n",
        "    return dataset\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Images loading using tf.data\n",
        "def tf_data(path, batch_size):\n",
        "    paths = tf.data.Dataset.list_files(path)\n",
        "    paths = paths.batch(64)\n",
        "    dataset = paths.map(prepare_data, tf.data.experimental.AUTOTUNE)\n",
        "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "    dataset = dataset.unbatch()\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.repeat()\n",
        "    return dataset\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-28T15:24:39.585404Z",
          "iopub.execute_input": "2023-05-28T15:24:39.585973Z",
          "iopub.status.idle": "2023-05-28T15:24:39.622119Z",
          "shell.execute_reply.started": "2023-05-28T15:24:39.585929Z",
          "shell.execute_reply": "2023-05-28T15:24:39.620884Z"
        },
        "trusted": true,
        "id": "IY8kuiYEQo5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Parameters setting: images width and height, depth, number if classes, input shape\n",
        "batch_size =  80\n",
        "img_width = 299\n",
        "img_height = 299\n",
        "depth = 3\n",
        "max_length = 300\n",
        "\n",
        "nClasses = sample_df['label_encode'].nunique()\n",
        "Classes = sample_df['label_encode'].unique()\n",
        "input_shape = (img_width, img_height, depth)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-28T15:24:42.211414Z",
          "iopub.execute_input": "2023-05-28T15:24:42.211942Z",
          "iopub.status.idle": "2023-05-28T15:24:42.219391Z",
          "shell.execute_reply.started": "2023-05-28T15:24:42.211898Z",
          "shell.execute_reply": "2023-05-28T15:24:42.218244Z"
        },
        "trusted": true,
        "id": "LXOvrDO0Qo5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "dataset = tf_data(sample_df, batch_size)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-28T15:24:43.589305Z",
          "iopub.execute_input": "2023-05-28T15:24:43.591957Z",
          "iopub.status.idle": "2023-05-28T15:24:44.141126Z",
          "shell.execute_reply.started": "2023-05-28T15:24:43.591907Z",
          "shell.execute_reply": "2023-05-28T15:24:44.139452Z"
        },
        "trusted": true,
        "id": "DllW4RIkQo5r",
        "outputId": "e6116ef2-b08e-46ee-db31-c5224730c6e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16\u001b[39m\n\u001b[0;32m----> 2\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtf_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[17], line 143\u001b[0m, in \u001b[0;36mtf_data\u001b[0;34m(path, batch_size)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtf_data\u001b[39m(path, batch_size):\n\u001b[0;32m--> 143\u001b[0m     paths \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m     paths \u001b[38;5;241m=\u001b[39m paths\u001b[38;5;241m.\u001b[39mbatch(\u001b[38;5;241m64\u001b[39m)\n\u001b[1;32m    145\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m paths\u001b[38;5;241m.\u001b[39mmap(prepare_data, tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mAUTOTUNE)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:1459\u001b[0m, in \u001b[0;36mDatasetV2.list_files\u001b[0;34m(file_pattern, shuffle, seed, name)\u001b[0m\n\u001b[1;32m   1457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1458\u001b[0m   shuffle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m-> 1459\u001b[0m file_pattern \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfile_pattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstring\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfile_pattern\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1461\u001b[0m matching_files \u001b[38;5;241m=\u001b[39m gen_io_ops\u001b[38;5;241m.\u001b[39mmatching_files(file_pattern)\n\u001b[1;32m   1463\u001b[0m \u001b[38;5;66;03m# Raise an exception if `file_pattern` does not match any files.\u001b[39;00m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/profiler/trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1636\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1627\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1628\u001b[0m           _add_error_prefix(\n\u001b[1;32m   1629\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversion_func\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m for type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1632\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1633\u001b[0m               name\u001b[38;5;241m=\u001b[39mname))\n\u001b[1;32m   1635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1636\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m   1639\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:343\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_tensor_conversion_function\u001b[39m(v, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    341\u001b[0m                                          as_ref\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    342\u001b[0m   _ \u001b[38;5;241m=\u001b[39m as_ref\n\u001b[0;32m--> 343\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:267\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    172\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:279\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    278\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> 279\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m g \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mget_default_graph()\n\u001b[1;32m    282\u001b[0m tensor_value \u001b[38;5;241m=\u001b[39m attr_value_pb2\u001b[38;5;241m.\u001b[39mAttrValue()\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:304\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[1;32m    303\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 304\u001b[0m   t \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type int)."
          ],
          "ename": "ValueError",
          "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type int).",
          "output_type": "error"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-28T09:39:01.944540Z",
          "iopub.execute_input": "2023-05-28T09:39:01.944969Z",
          "iopub.status.idle": "2023-05-28T09:39:01.951797Z",
          "shell.execute_reply.started": "2023-05-28T09:39:01.944931Z",
          "shell.execute_reply": "2023-05-28T09:39:01.950849Z"
        },
        "trusted": true,
        "id": "7F9hE3pMQo5r",
        "outputId": "c13ab1b0-f3be-463e-c725-b9615f54256a"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 79,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<PrefetchDataset element_spec=(TensorSpec(shape=<unknown>, dtype=tf.int32, name=None), TensorSpec(shape=<unknown>, dtype=tf.int32, name=None), TensorSpec(shape=<unknown>, dtype=tf.int32, name=None), TensorSpec(shape=<unknown>, dtype=tf.float32, name=None), TensorSpec(shape=<unknown>, dtype=tf.int32, name=None))>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = next(iter(dataset))\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-28T09:40:13.689255Z",
          "iopub.execute_input": "2023-05-28T09:40:13.689700Z",
          "iopub.status.idle": "2023-05-28T09:40:13.904461Z",
          "shell.execute_reply.started": "2023-05-28T09:40:13.689664Z",
          "shell.execute_reply": "2023-05-28T09:40:13.903390Z"
        },
        "trusted": true,
        "id": "CuK2qrm4Qo5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ip, op = data"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-28T09:40:16.411644Z",
          "iopub.execute_input": "2023-05-28T09:40:16.412071Z",
          "iopub.status.idle": "2023-05-28T09:40:16.436747Z",
          "shell.execute_reply.started": "2023-05-28T09:40:16.412036Z",
          "shell.execute_reply": "2023-05-28T09:40:16.435053Z"
        },
        "trusted": true,
        "id": "aP005M4bQo5r",
        "outputId": "e1e33916-d28c-4e9a-b731-aef9211c4fd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[85], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ip, op \u001b[38;5;241m=\u001b[39m data\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ],
          "ename": "ValueError",
          "evalue": "too many values to unpack (expected 2)",
          "output_type": "error"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images = ip['image'][:16]\n",
        "title = ip['title'][:16]\n",
        "true_labels =  op['output'][:16]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-27T11:52:44.180340Z",
          "iopub.execute_input": "2023-05-27T11:52:44.181716Z",
          "iopub.status.idle": "2023-05-27T11:52:44.190332Z",
          "shell.execute_reply.started": "2023-05-27T11:52:44.181672Z",
          "shell.execute_reply": "2023-05-27T11:52:44.188682Z"
        },
        "trusted": true,
        "id": "AlidVRWqQo5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_labels"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-27T11:52:54.007446Z",
          "iopub.execute_input": "2023-05-27T11:52:54.008136Z",
          "iopub.status.idle": "2023-05-27T11:52:54.018899Z",
          "shell.execute_reply.started": "2023-05-27T11:52:54.008085Z",
          "shell.execute_reply": "2023-05-27T11:52:54.017279Z"
        },
        "trusted": true,
        "id": "k3EyNdJ2Qo5r",
        "outputId": "2d9c5c7d-ad63-4cc8-813a-54135d1723c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 176,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<tf.Tensor: shape=(16,), dtype=int64, numpy=array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import callbacks\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import utils\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import applications\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.regularizers import l2, l1\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import glob\n",
        "import os\n",
        "import cv2\n",
        "import sys\n",
        "import pickle\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-27T11:57:24.721236Z",
          "iopub.execute_input": "2023-05-27T11:57:24.721698Z",
          "iopub.status.idle": "2023-05-27T11:57:25.939432Z",
          "shell.execute_reply.started": "2023-05-27T11:57:24.721669Z",
          "shell.execute_reply": "2023-05-27T11:57:25.938120Z"
        },
        "trusted": true,
        "id": "PhP5RWCjQo5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Images Model\n",
        "model_cnn = models.Sequential()\n",
        "model_cnn.add(InceptionV3(weights='imagenet', include_top=False, input_tensor=layers.Input(shape=(299, 299, 3))))\n",
        "model_cnn.add(layers.AveragePooling2D(pool_size=(8, 8), name='AVG_Pooling'))\n",
        "model_cnn.add(layers.Dropout(.4, name='Dropout_0.4'))\n",
        "model_cnn.add(layers.Flatten(name='Flatten'))\n",
        "model_cnn.add(layers.Dense(128, name='Dense_128'))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-27T11:57:28.403507Z",
          "iopub.execute_input": "2023-05-27T11:57:28.404029Z",
          "iopub.status.idle": "2023-05-27T11:57:33.592464Z",
          "shell.execute_reply.started": "2023-05-27T11:57:28.403989Z",
          "shell.execute_reply": "2023-05-27T11:57:33.591244Z"
        },
        "trusted": true,
        "id": "e0sfqCKvQo5s",
        "outputId": "639fbc64-05b5-46a7-f3dd-7d7aa5e4a4e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n87910968/87910968 [==============================] - 1s 0us/step\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep model layers trainable\n",
        "for layer in model_cnn.layers:\n",
        "    layer.trainable = True"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-27T11:57:49.840726Z",
          "iopub.execute_input": "2023-05-27T11:57:49.841180Z",
          "iopub.status.idle": "2023-05-27T11:57:49.864329Z",
          "shell.execute_reply.started": "2023-05-27T11:57:49.841149Z",
          "shell.execute_reply": "2023-05-27T11:57:49.862741Z"
        },
        "trusted": true,
        "id": "042FrRuGQo5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_cnn.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-27T11:57:57.748438Z",
          "iopub.execute_input": "2023-05-27T11:57:57.748935Z",
          "iopub.status.idle": "2023-05-27T11:57:57.806107Z",
          "shell.execute_reply.started": "2023-05-27T11:57:57.748901Z",
          "shell.execute_reply": "2023-05-27T11:57:57.804660Z"
        },
        "trusted": true,
        "id": "sEFUVBLyQo5s",
        "outputId": "8aadce3d-7f8f-4239-e039-de3c1c420e46"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n inception_v3 (Functional)   (None, 8, 8, 2048)        21802784  \n                                                                 \n AVG_Pooling (AveragePooling  (None, 1, 1, 2048)       0         \n 2D)                                                             \n                                                                 \n Dropout_0.4 (Dropout)       (None, 1, 1, 2048)        0         \n                                                                 \n Flatten (Flatten)           (None, 2048)              0         \n                                                                 \n Dense_128 (Dense)           (None, 128)               262272    \n                                                                 \n=================================================================\nTotal params: 22,065,056\nTrainable params: 22,030,624\nNon-trainable params: 34,432\n_________________________________________________________________\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model_cnn, to_file='model_cnn.png')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-27T11:58:05.491360Z",
          "iopub.execute_input": "2023-05-27T11:58:05.491820Z",
          "iopub.status.idle": "2023-05-27T11:58:05.704463Z",
          "shell.execute_reply.started": "2023-05-27T11:58:05.491788Z",
          "shell.execute_reply": "2023-05-27T11:58:05.703158Z"
        },
        "trusted": true,
        "id": "qYH8C3agQo5s",
        "outputId": "79139a36-a04a-4a9c-f3a0-372c481334e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 185,
          "output_type": "execute_result",
          "data": {
            "image/png": "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",
            "text/plain": "<IPython.core.display.Image object>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bert + LSTM text model\n",
        "input_ids = layers.Input(shape=(max_length,), dtype=tf.int32, name=\"input_word_ids\")\n",
        "input_masks = layers.Input(shape=(max_length,), dtype=tf.int32, name=\"input_masks\")\n",
        "input_segments = layers.Input(shape=(max_length,), dtype=tf.int32, name=\"segment_ids\")\n",
        "_, seq_out = bert_layer([input_ids, input_masks, input_segments])\n",
        "out = layers.LSTM(128, name='LSTM')(seq_out)\n",
        "model_lstm = models.Model([input_ids, input_masks, input_segments], out)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-27T11:59:16.727346Z",
          "iopub.execute_input": "2023-05-27T11:59:16.727764Z",
          "iopub.status.idle": "2023-05-27T11:59:19.873406Z",
          "shell.execute_reply.started": "2023-05-27T11:59:16.727735Z",
          "shell.execute_reply": "2023-05-27T11:59:19.872126Z"
        },
        "trusted": true,
        "id": "G5p4d8tCQo5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep the Bert + LSTM layers trainable\n",
        "for layer in model_lstm.layers:\n",
        "    layer.trainable = True"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-27T11:59:32.204231Z",
          "iopub.execute_input": "2023-05-27T11:59:32.204715Z",
          "iopub.status.idle": "2023-05-27T11:59:32.212158Z",
          "shell.execute_reply.started": "2023-05-27T11:59:32.204683Z",
          "shell.execute_reply": "2023-05-27T11:59:32.210629Z"
        },
        "trusted": true,
        "id": "qN_7hiT6Qo5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_lstm.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-27T11:59:39.089622Z",
          "iopub.execute_input": "2023-05-27T11:59:39.090157Z",
          "iopub.status.idle": "2023-05-27T11:59:39.136250Z",
          "shell.execute_reply.started": "2023-05-27T11:59:39.090122Z",
          "shell.execute_reply": "2023-05-27T11:59:39.134768Z"
        },
        "trusted": true,
        "id": "8NHuuCeHQo5t",
        "outputId": "da33b19e-4e96-4695-f6ba-e40cb73555c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Model: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_word_ids (InputLayer)    [(None, 512)]        0           []                               \n                                                                                                  \n input_masks (InputLayer)       [(None, 512)]        0           []                               \n                                                                                                  \n segment_ids (InputLayer)       [(None, 512)]        0           []                               \n                                                                                                  \n keras_layer (KerasLayer)       [(None, 1024),       335141889   ['input_word_ids[0][0]',         \n                                 (None, 512, 1024)]               'input_masks[0][0]',            \n                                                                  'segment_ids[0][0]']            \n                                                                                                  \n LSTM (LSTM)                    (None, 128)          590336      ['keras_layer[0][1]']            \n                                                                                                  \n==================================================================================================\nTotal params: 335,732,225\nTrainable params: 335,732,224\nNon-trainable params: 1\n__________________________________________________________________________________________________\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(model_lstm, to_file='bert_lstm.png')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-27T11:59:51.375400Z",
          "iopub.execute_input": "2023-05-27T11:59:51.375893Z",
          "iopub.status.idle": "2023-05-27T11:59:51.454471Z",
          "shell.execute_reply.started": "2023-05-27T11:59:51.375861Z",
          "shell.execute_reply": "2023-05-27T11:59:51.453276Z"
        },
        "trusted": true,
        "id": "VXRljR6uQo5t",
        "outputId": "357fade4-ef5f-435f-a4ab-97a77c779824"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 191,
          "output_type": "execute_result",
          "data": {
            "image/png": "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",
            "text/plain": "<IPython.core.display.Image object>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stacking early-fusion multimodal model\n",
        "\n",
        "input_word_ids = layers.Input(shape=(max_length,), dtype=tf.int32,\n",
        "                                       name=\"input_word_ids\")\n",
        "input_mask = layers.Input(shape=(max_length,), dtype=tf.int32,\n",
        "                                   name=\"input_mask\")\n",
        "segment_ids = layers.Input(shape=(max_length,), dtype=tf.int32,\n",
        "                                    name=\"segment_ids\")\n",
        "image_input = layers.Input(shape = input_shape, dtype=tf.float32,\n",
        "                           name = \"image\")\n",
        "\n",
        "image_side = model_cnn(image_input)\n",
        "text_side = model_lstm([input_word_ids, input_mask, segment_ids])\n",
        "# Concatenate features from images and texts\n",
        "merged = layers.Concatenate()([image_side, text_side])\n",
        "merged = layers.Dense(256, activation = 'relu')(merged)\n",
        "output = layers.Dense(nClasses, activation='softmax', name = \"class\")(merged)"
      ],
      "metadata": {
        "id": "Em7VrTbgQo5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Model([input_word_ids, input_mask, segment_ids, image_input], output)"
      ],
      "metadata": {
        "id": "AWXrGPYVQo5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "BlV8rkVFQo5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model, to_file='multimodal.png')"
      ],
      "metadata": {
        "id": "MVSNsbvSQo5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stochastic Gradient Descent optimizer\n",
        "sgd = optimizers.SGD(learning_rate=0.0001, momentum=0.9, nesterov=False)\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=sgd,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "PvxBB4iYQo5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup callbacks, logs and early stopping condition\n",
        "checkpoint_path = \"stacking_early_fusion/weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "cp = callbacks.ModelCheckpoint(checkpoint_path, monitor='val_accuracy',save_best_only=True,verbose=1, mode='max')\n",
        "csv_logger = callbacks.CSVLogger('stacking_early_fusion/stacking_early.log')\n",
        "es = callbacks.EarlyStopping(patience = 3, restore_best_weights=True)"
      ],
      "metadata": {
        "id": "rMolFzFFQo5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce learning rate if no improvement is observed\n",
        "reduce_lr = callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_accuracy', factor=0.1, patience=1, min_lr=0.00001)"
      ],
      "metadata": {
        "id": "NvWQdkFOQo5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model weights\n",
        "model.load_weights('stacking_early_fusion/weights-improvement-16-0.92.hdf5')"
      ],
      "metadata": {
        "id": "nGLR3mkoQo5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "history = model.fit(data_train,\n",
        "                  epochs=15,\n",
        "                  steps_per_epoch = train.shape[0]//batch_size,\n",
        "                  validation_data = data_test,\n",
        "                   validation_steps = test.shape[0]//batch_size,\n",
        "                 callbacks=[cp, csv_logger, reduce_lr])"
      ],
      "metadata": {
        "id": "FB7TfN3eQo5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and test accuracy using Plotly library\n",
        "df = pd.read_csv('stacking_early_fusion/stacking_early.log')\n",
        "\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=df['epoch'], y=df['accuracy'],\n",
        "                    mode='lines',\n",
        "                    name='training'))\n",
        "\n",
        "fig.add_trace(go.Scatter(x=df['epoch'], y=df['val_accuracy'],\n",
        "                    mode='lines',\n",
        "                    name='test'))\n",
        "\n",
        "fig.update_layout(\n",
        "    font_size = 20,\n",
        "    paper_bgcolor='rgba(0,0,0,0)',\n",
        "    plot_bgcolor='rgba(0,0,0,0)',\n",
        ")\n",
        "\n",
        "fig.update_xaxes(showgrid=True, gridwidth=0.5, gridcolor='Gray')\n",
        "fig.update_yaxes(showgrid=True, gridwidth=0.5, gridcolor='Gray')"
      ],
      "metadata": {
        "id": "wQDh30CRQo5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and test loss using Plotly library\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=df['epoch'], y=df['loss'],\n",
        "                    mode='lines',\n",
        "                    name='training'))\n",
        "\n",
        "fig.add_trace(go.Scatter(x=df['epoch'], y=df['val_loss'],\n",
        "                    mode='lines',\n",
        "                    name='test'))\n",
        "\n",
        "fig.update_layout(\n",
        "    font_size = 20,\n",
        "    paper_bgcolor='rgba(0,0,0,0)',\n",
        "    plot_bgcolor='rgba(0,0,0,0)',\n",
        ")\n",
        "\n",
        "fig.update_xaxes(showgrid=True, gridwidth=0.5, gridcolor='Gray')\n",
        "fig.update_yaxes(showgrid=True, gridwidth=0.5, gridcolor='Gray')"
      ],
      "metadata": {
        "id": "GjgbWmPQQo5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model evaluation on test set\n",
        "model.evaluate(data_test,\n",
        "               steps = test.shape[0]//batch_size)"
      ],
      "metadata": {
        "id": "j286kRnNQo5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "CxcppJGUQo5u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 아래 필요 x"
      ],
      "metadata": {
        "id": "SKLgumboQo5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "# BERT 토크나이저 준비\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# 텍스트 전처리 함수\n",
        "def preprocess_text(sen):\n",
        "    # HTML 태그 제거\n",
        "    sentence = remove_tags(sen)\n",
        "    # 구두점과 숫자 제거\n",
        "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
        "    # 단일 문자 제거\n",
        "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
        "    # 여러 개의 공백 제거\n",
        "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
        "    sentence = sentence.lower()\n",
        "    return sentence\n",
        "\n",
        "# HTML 태그 제거 함수\n",
        "def remove_tags(text):\n",
        "    if isinstance(text, str):\n",
        "        return TAG_RE.sub('', text)\n",
        "    else:\n",
        "        return ''\n",
        "\n",
        "\n",
        "TAG_RE = re.compile(r'<[^>]+>')\n",
        "\n",
        "# 이미지 로드 및 전처리 함수\n",
        "def load_image(img_path):\n",
        "    img = tf.io.read_file(img_path)  # 이미지 파일을 바이트 스트링으로 읽어옴\n",
        "    img = tf.image.decode_jpeg(img, channels=3)  # JPEG 이미지를 디코딩하여 텐서로 변환\n",
        "    img = tf.image.resize(img, (229, 229))  # 이미지 크기 조정\n",
        "    img = img / 255.0  # 정규화\n",
        "    return img\n",
        "\n",
        "\n",
        "\n",
        "def create_dataset(df, batch_size):\n",
        "    # 이미지 경로 추출\n",
        "    image_paths = df['image_path'].values\n",
        "\n",
        "    # 이미지 데이터셋 생성\n",
        "    images = tf.data.Dataset.from_tensor_slices((df, image_paths))\n",
        "    images = images.map(lambda x, y: load_image(x, y), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    # 텍스트 데이터셋 생성\n",
        "    texts = tf.data.Dataset.from_tensor_slices(df['Title'].values)\n",
        "\n",
        "    # 데이터셋 병합\n",
        "    dataset = tf.data.Dataset.zip((images, texts))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "\n",
        "# 텍스트 전처리 및 BERT 입력 생성 함수\n",
        "def prepare_text(texts, tokenizer, max_length):\n",
        "    texts = [preprocess_text(text) for text in texts]\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    token_type_ids = []\n",
        "    for text in texts:\n",
        "        encoded_text = tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='tf'\n",
        "        )\n",
        "        input_ids.append(encoded_text['input_ids'][0])\n",
        "        attention_masks.append(encoded_text['attention_mask'][0])\n",
        "        token_type_ids.append(encoded_text['token_type_ids'][0])\n",
        "    return {\n",
        "        'input_ids': np.array(input_ids),\n",
        "        'attention_masks': np.array(attention_masks),\n",
        "        'token_type_ids': np.array(token_type_ids)\n",
        "    }\n",
        "\n",
        "# 이미지와 텍스트 데이터를 로드하고 전처리하여 모델에 입력 형식으로 변환하는 함수\n",
        "def prepare_data(image_paths, titles, labels):\n",
        "    images = load_image(image_paths)\n",
        "    texts = prepare_text(titles, tokenizer, max_length)\n",
        "    return (images, texts), labels\n",
        "\n",
        "\n",
        "\n",
        "def create_dataset(df, batch_size):\n",
        "    # 이미지 경로 추출\n",
        "    image_paths = df['image_path'].values\n",
        "\n",
        "    # 이미지 데이터셋 생성\n",
        "    images = tf.data.Dataset.from_tensor_slices(image_paths)\n",
        "    images = images.map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    # 텍스트 데이터셋 생성\n",
        "    texts = tf.data.Dataset.from_tensor_slices(df['Title'].values)\n",
        "    texts = texts.map(preprocess_text, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    # 레이블 데이터셋 생성\n",
        "    labels = df['label_encode'].values\n",
        "\n",
        "    # 데이터셋 병합\n",
        "    dataset = tf.data.Dataset.zip((images, texts))\n",
        "    dataset = dataset.map(lambda x, y: (x, y, labels))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "\n",
        "    return dataset\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-27T11:35:13.694244Z",
          "iopub.execute_input": "2023-05-27T11:35:13.694836Z",
          "iopub.status.idle": "2023-05-27T11:35:13.923906Z",
          "shell.execute_reply.started": "2023-05-27T11:35:13.694795Z",
          "shell.execute_reply": "2023-05-27T11:35:13.922393Z"
        },
        "trusted": true,
        "id": "6x8CpzdRQo5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 생성\n",
        "batch_size = 16\n",
        "dataset = create_dataset(sample_df, batch_size)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-27T11:35:15.767601Z",
          "iopub.execute_input": "2023-05-27T11:35:15.768227Z",
          "iopub.status.idle": "2023-05-27T11:35:15.923328Z",
          "shell.execute_reply.started": "2023-05-27T11:35:15.768183Z",
          "shell.execute_reply": "2023-05-27T11:35:15.921923Z"
        },
        "trusted": true,
        "id": "TANQYbS2Qo5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-27T11:46:41.483511Z",
          "iopub.execute_input": "2023-05-27T11:46:41.484141Z",
          "iopub.status.idle": "2023-05-27T11:46:41.494172Z",
          "shell.execute_reply.started": "2023-05-27T11:46:41.484094Z",
          "shell.execute_reply": "2023-05-27T11:46:41.492642Z"
        },
        "trusted": true,
        "id": "WMLNSd2SQo5u",
        "outputId": "9307a74e-d95a-4a9a-d840-dbed32d0830a"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 147,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<BatchDataset element_spec=(TensorSpec(shape=(None, 229, 229, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None, 984), dtype=tf.int64, name=None))>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KI8mzf3QQo5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ip, op, labels = next(iter(dataset))\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-27T11:46:45.937921Z",
          "iopub.execute_input": "2023-05-27T11:46:45.939307Z",
          "iopub.status.idle": "2023-05-27T11:46:46.002912Z",
          "shell.execute_reply.started": "2023-05-27T11:46:45.939205Z",
          "shell.execute_reply": "2023-05-27T11:46:46.001172Z"
        },
        "trusted": true,
        "id": "koRNcV_7Qo5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# 이미지 입력 모델 (InceptionV3)\n",
        "image_input = layers.Input(shape=(img_width, img_height, depth), name='image_input')\n",
        "image_model = tf.keras.applications.InceptionV3(input_tensor=image_input, include_top=False, weights='imagenet')\n",
        "image_model.trainable = False\n",
        "\n",
        "# 텍스트 입력 모델 (BERT)\n",
        "text_input = layers.Input(shape=(max_length,), dtype=tf.int32, name='text_input')\n",
        "text_model = bert_layer([text_input['input_ids'], text_input['input_mask'], text_input['segment_ids']])[1]\n",
        "\n",
        "# 모델 결합\n",
        "combined_model = layers.concatenate([image_model.output, text_model])\n",
        "combined_model = layers.Dense(512, activation='relu')(combined_model)\n",
        "combined_model = layers.Dropout(0.5)(combined_model)\n",
        "combined_model = layers.Dense(nClasses, activation='softmax')(combined_model)\n",
        "\n",
        "# 최종 모델 정의\n",
        "model = tf.keras.Model(inputs=[image_input, text_input], outputs=combined_model)\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "7gMbyVJiQo5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "epochs = 10\n",
        "\n",
        "dataset = create_dataset(sample_df, batch_size)\n",
        "\n",
        "model.fit(dataset, epochs=epochs)\n"
      ],
      "metadata": {
        "id": "BVYGMiMmQo5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vZf5NOdBQo5u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}